{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Communes data preparation - French geographic reference\n",
    "\n",
    "**Project: Analysis of cultural accessibility and territorial inequalities in France**\n",
    "\n",
    "### Research Questions:\n",
    "1. Geographic Distribution: How is cultural supply distributed across French territories?\n",
    "2. Urban vs Rural: Are there significant disparities between urban and rural areas?\n",
    "3. Socio-Economic Correlation: Is there a relationship between territorial wealth and cultural supply?\n",
    "4. Typological Diversity: What types of cultural venues exist and how are they distributed?\n",
    "5. PACA Regional Focus: How does PACA compare to national averages?\n",
    "6. How is public music infrastructure distributed across French departments?\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "**Source:** API Découpage Administratif (French Government)\n",
    "\n",
    "**Name:** Communes - French Administrative Divisions\n",
    "\n",
    "**Origin:** Official government API providing up-to-date administrative data\n",
    "\n",
    "**Data:** 2025 (continuously updated)\n",
    "\n",
    "**Last Update:** Real-time (API is always current)\n",
    "\n",
    "**Content:** All French communes (~35,000) with codes, names, coordinates, population\n",
    "\n",
    "**File Location:** `data/raw/geography/communes.json`\n",
    "\n",
    "**Download:** Already downloaded via API (or use script below)\n",
    "\n",
    "**API URL:** https://geo.api.gouv.fr/communes?fields=nom,code,codesPostaux,codeDepartement,codeRegion,population&format=json&geometry=centre\n",
    "\n",
    "**Purpose:** Reference table for commune names, codes, and basic info\n",
    "\n",
    "**Key columns:**\n",
    "- `code`: INSEE commune code (5 digits)\n",
    "- `nom`: Commune name\n",
    "- `codesPostaux`: Postal code(s)\n",
    "- `codeDepartement`: Department code\n",
    "- `codeRegion`: Region code\n",
    "- `population`: Population estimate\n",
    "- `centre.coordinates`: Lat/Lon of commune center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json                             # json : javascript object notation\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "api-download",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#import os\n",
    "\n",
    "#url = \"https://geo.api.gouv.fr/communes?fields=nom,code,codesPostaux,codeDepartement,codeRegion,population&format=json&geometry=centre\"\n",
    "\n",
    "#print(\"Downloading communes from API...\")\n",
    "#response = requests.get(url)\n",
    "\n",
    "# notes : https://ec.europa.eu/eurostat/fr/web/user-guides/data-browser/api-data-access/api-faq/examples\n",
    "#         https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "#         json.load() ; with open() ; pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {},
   "source": [
    "## Load Communes Data from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/geography/communes.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load JSON file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/raw/geography/communes.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     communes_data = json.load(f)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Bureau\\ironhack\\UNIT4\\first_project\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/raw/geography/communes.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load JSON file\n",
    "with open('data/raw/geography/communes.json', 'r', encoding='utf-8') as f:\n",
    "    communes_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_communes = pd.DataFrame(communes_data)\n",
    "print(f\"{len(df_communes):,} communes\")\n",
    "print(f\"Columns: {len(df_communes.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "head",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_communes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cols",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_communes.shape\n",
    "print(df_communes.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "df_communes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean",
   "metadata": {},
   "source": [
    "## CSV preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-codes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle postal codes (can be a list)\n",
    "if 'codesPostaux' in df_communes.columns:\n",
    "    # Take first postal code if multiple\n",
    "    df_communes['postal_code'] = df_communes['codesPostaux'].apply(\n",
    "        lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for SQL\n",
    "df_communes_clean = df_communes[[\n",
    "    'code',\n",
    "    'nom',\n",
    "    'postal_code',\n",
    "    'codeDepartement',\n",
    "    'codeRegion',\n",
    "    'population'\n",
    "]].copy()\n",
    "\n",
    "print(f\"{len(df_communes_clean.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "df_communes_clean.columns = [\n",
    "    'commune_code',\n",
    "    'commune_name',\n",
    "    'postal_code',\n",
    "    'dept_code',\n",
    "    'region_code',\n",
    "    'population']\n",
    "\n",
    "print(df_communes_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual verification :  correct data types\n",
    "df_communes_clean['commune_code'] = df_communes_clean['commune_code'].astype(str).str.zfill(5)\n",
    "df_communes_clean['postal_code'] = df_communes_clean['postal_code'].astype(str).str.zfill(5)\n",
    "df_communes_clean['population'] = pd.to_numeric(df_communes_clean['population'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df_communes_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values:\")\n",
    "print(df_communes_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062510d-d1ff-4e7f-aaf6-146ecd9f16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communes by department\n",
    "print( \"Number of communes by department\")\n",
    "communes_per_dept = df_communes_clean['dept_code'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 departments with most communes:\")\n",
    "print(communes_per_dept.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communes by region\n",
    "print(\"Number of communes by region\")\n",
    "communes_per_region = df_communes_clean['region_code'].value_counts().sort_values(ascending=False)\n",
    "print(communes_per_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PACA communes             \n",
    "# PACA : PRovence-Alpes-Côte-d'Azur\n",
    "# PACA region code is '93'\n",
    "\n",
    "paca_communes = df_communes_clean[df_communes_clean['region_code'] == '93']\n",
    "\n",
    "print(f\"PACA REGION\")\n",
    "print(f\"Total communes in PACA: {len(paca_communes):,}\")\n",
    "print(f\"Total population: {paca_communes['population'].sum():,}\")\n",
    "\n",
    "print(\"\\nCommunes per PACA department:\")\n",
    "paca_by_dept = paca_communes['dept_code'].value_counts().sort_index()\n",
    "print(paca_by_dept)\n",
    "\n",
    "# Department names\n",
    "dept_names = {\n",
    "    '04': 'Alpes-de-Haute-Provence',\n",
    "    '05': 'Hautes-Alpes',\n",
    "    '06': 'Alpes-Maritimes',\n",
    "    '13': 'Bouches-du-Rhône',\n",
    "    '83': 'Var',\n",
    "    '84': 'Vaucluse'\n",
    "}\n",
    "\n",
    "print(\"\\nWith names:\")\n",
    "for code, count in paca_by_dept.items():\n",
    "    print(f\"{code} - {dept_names.get(code, 'Unknown'):30s}: {count:3d} communes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Largest communes by population\n",
    "\n",
    "largest = df_communes_clean.nlargest(20, 'population')[['commune_name', 'dept_code', 'population']]\n",
    "print(largest.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## Files for SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "output_file = 'data/processed/communes_for_sql.csv'\n",
    "df_communes_clean.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"   Rows: {len(df_communes_clean):,}\")\n",
    "print(f\"   Columns: {len(df_communes_clean.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
